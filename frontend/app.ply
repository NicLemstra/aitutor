import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import UnstructuredPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
import tempfile
import os

st.set_page_config(page_title="ðŸ“˜ AI Tutor", layout="wide")
st.title("ðŸ“š AI Tutor - Multi-Course Mode")

# ---------------------- Session State Setup ----------------------
if "courses" not in st.session_state:
    st.session_state.courses = {}

if "current_course" not in st.session_state:
    st.session_state.current_course = None

# ---------------------- Course Selection ----------------------
course_names = list(st.session_state.courses.keys())
selected_course = st.selectbox("Select a course", course_names + ["âž• Create new course"])

if selected_course == "âž• Create new course":
    new_course_name = st.text_input("Enter new course name")
    if st.button("Create Course") and new_course_name:
        st.session_state.current_course = new_course_name
        st.session_state.courses[new_course_name] = {
            "chain": None,
            "chat_history": []
        }
        st.experimental_rerun()
else:
    st.session_state.current_course = selected_course

course = st.session_state.courses.get(st.session_state.current_course)

# ---------------------- Upload & Train PDF ----------------------
if course:
    st.header(f"ðŸ“˜ Course: {st.session_state.current_course}")
    if not course["chain"]:
        uploaded_file = st.file_uploader("Upload a class PDF", type=["pdf"])
        if uploaded_file:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name

            st.success("âœ… PDF uploaded. Preparing tutor...")

            loader = UnstructuredPDFLoader(tmp_path)
            docs = loader.load()
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            chunks = splitter.split_documents(docs)
            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(chunks, embeddings)
            llm = ChatOpenAI(model_name="gpt-4", temperature=0)

            course["chain"] = ConversationalRetrievalChain.from_llm(
                llm=llm,
                retriever=vectorstore.as_retriever()
            )
            st.success("ðŸŽ“ Tutor is ready!")
    else:
        st.subheader("ðŸ’¬ Chat With Your Tutor")
        query = st.text_input("Ask a question:")
        if query:
            result = course["chain"]({
                "question": query,
                "chat_history": course["chat_history"]
            })
            course["chat_history"].append((query, result["answer"]))

        for q, a in course["chat_history"]:
            st.markdown(f"**You:** {q}")
            st.markdown(f"**Tutor:** {a}")
